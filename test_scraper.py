#!/usr/bin/env python3
"""
æœ¬åœ°æµ‹è¯•è„šæœ¬ - æµ‹è¯•Leverçˆ¬è™«åŠŸèƒ½
"""

import sys
import os
import json
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from utils.scraper_utils import LeverScraperUtils

def test_scraper():
    """æµ‹è¯•çˆ¬è™«åŠŸèƒ½"""
    print("ğŸ§ª å¼€å§‹æµ‹è¯•Leverçˆ¬è™«...")
    
    # åˆå§‹åŒ–çˆ¬è™«å·¥å…·
    scraper = LeverScraperUtils()
    
    # æµ‹è¯•è·å–å…¬å¸åˆ—è¡¨
    print("ğŸ“‹ æµ‹è¯•è·å–å…¬å¸åˆ—è¡¨...")
    companies = scraper.get_company_list_from_api()
    print(f"å‘ç° {len(companies)} ä¸ªå…¬å¸")
    
    if companies:
        # æµ‹è¯•å‰3ä¸ªå…¬å¸
        test_companies = companies[:3]
        print(f"æµ‹è¯•å…¬å¸: {test_companies}")
        
        all_jobs = []
        
        for company in test_companies:
            print(f"\nğŸ¢ æµ‹è¯•å…¬å¸: {company}")
            jobs = scraper.get_jobs_from_company_page(company)
            print(f"è·å–åˆ° {len(jobs)} ä¸ªèŒä½")
            
            # è¿‡æ»¤æ¾³æ´²èŒä½
            australian_jobs = [job for job in jobs if scraper.is_australian_job(job)]
            print(f"å…¶ä¸­ {len(australian_jobs)} ä¸ªæ¾³æ´²èŒä½")
            
            all_jobs.extend(australian_jobs)
            
            # æ˜¾ç¤ºå‰2ä¸ªèŒä½è¯¦æƒ…
            for i, job in enumerate(australian_jobs[:2]):
                print(f"\nèŒä½ {i+1}:")
                print(f"  æ ‡é¢˜: {job.get('job_title', 'N/A')}")
                print(f"  å…¬å¸: {job.get('company_name', 'N/A')}")
                print(f"  åœ°ç‚¹: {job.get('location', 'N/A')}")
                print(f"  URL: {job.get('job_url', 'N/A')}")
        
        # ä¿å­˜æµ‹è¯•ç»“æœ
        if all_jobs:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"test_results_{timestamp}.json"
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(all_jobs, f, ensure_ascii=False, indent=2)
            
            print(f"\nâœ… æµ‹è¯•å®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°: {filename}")
            print(f"æ€»å…±è·å–åˆ° {len(all_jobs)} ä¸ªæ¾³æ´²èŒä½")
        else:
            print("\nâš ï¸ æœªè·å–åˆ°ä»»ä½•æ¾³æ´²èŒä½")
    else:
        print("âŒ æœªè·å–åˆ°å…¬å¸åˆ—è¡¨")

def test_specific_company(company_slug: str):
    """æµ‹è¯•ç‰¹å®šå…¬å¸"""
    print(f"ğŸ§ª æµ‹è¯•ç‰¹å®šå…¬å¸: {company_slug}")
    
    scraper = LeverScraperUtils()
    jobs = scraper.get_jobs_from_company_page(company_slug)
    
    print(f"è·å–åˆ° {len(jobs)} ä¸ªèŒä½")
    
    australian_jobs = [job for job in jobs if scraper.is_australian_job(job)]
    print(f"å…¶ä¸­ {len(australian_jobs)} ä¸ªæ¾³æ´²èŒä½")
    
    for i, job in enumerate(australian_jobs):
        print(f"\nèŒä½ {i+1}:")
        print(f"  æ ‡é¢˜: {job.get('job_title', 'N/A')}")
        print(f"  å…¬å¸: {job.get('company_name', 'N/A')}")
        print(f"  åœ°ç‚¹: {job.get('location', 'N/A')}")
        print(f"  éƒ¨é—¨: {job.get('department', 'N/A')}")
        print(f"  å›¢é˜Ÿ: {job.get('team', 'N/A')}")
        print(f"  URL: {job.get('job_url', 'N/A')}")
        print(f"  æè¿°: {job.get('description', 'N/A')[:200]}...")

if __name__ == "__main__":
    if len(sys.argv) > 1:
        # æµ‹è¯•ç‰¹å®šå…¬å¸
        company_slug = sys.argv[1]
        test_specific_company(company_slug)
    else:
        # è¿è¡Œå®Œæ•´æµ‹è¯•
        test_scraper() 